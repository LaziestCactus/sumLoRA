{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 7.355959415435791,
      "learning_rate": 2.5e-05,
      "loss": 14.8181,
      "step": 1
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.454519271850586,
      "learning_rate": 5e-05,
      "loss": 14.3246,
      "step": 2
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.966183185577393,
      "learning_rate": 4.8958333333333335e-05,
      "loss": 14.4451,
      "step": 3
    },
    {
      "epoch": 4.0,
      "grad_norm": 9.398688316345215,
      "learning_rate": 4.791666666666667e-05,
      "loss": 15.1266,
      "step": 4
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.68294906616211,
      "learning_rate": 4.6875e-05,
      "loss": 13.9192,
      "step": 5
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.844062805175781,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 14.9442,
      "step": 6
    },
    {
      "epoch": 7.0,
      "grad_norm": 8.744599342346191,
      "learning_rate": 4.4791666666666673e-05,
      "loss": 14.4892,
      "step": 7
    },
    {
      "epoch": 8.0,
      "grad_norm": 6.0678510665893555,
      "learning_rate": 4.375e-05,
      "loss": 13.8938,
      "step": 8
    },
    {
      "epoch": 9.0,
      "grad_norm": 8.047998428344727,
      "learning_rate": 4.270833333333333e-05,
      "loss": 14.7665,
      "step": 9
    },
    {
      "epoch": 10.0,
      "grad_norm": 7.437812805175781,
      "learning_rate": 4.166666666666667e-05,
      "loss": 13.6483,
      "step": 10
    },
    {
      "epoch": 11.0,
      "grad_norm": 7.618201732635498,
      "learning_rate": 4.0625000000000005e-05,
      "loss": 14.0551,
      "step": 11
    },
    {
      "epoch": 12.0,
      "grad_norm": 8.623459815979004,
      "learning_rate": 3.958333333333333e-05,
      "loss": 13.7475,
      "step": 12
    },
    {
      "epoch": 13.0,
      "grad_norm": 7.2431960105896,
      "learning_rate": 3.854166666666667e-05,
      "loss": 13.8806,
      "step": 13
    },
    {
      "epoch": 14.0,
      "grad_norm": 7.538437366485596,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 13.9604,
      "step": 14
    },
    {
      "epoch": 15.0,
      "grad_norm": 7.502803802490234,
      "learning_rate": 3.6458333333333336e-05,
      "loss": 13.453,
      "step": 15
    },
    {
      "epoch": 16.0,
      "grad_norm": 6.468360900878906,
      "learning_rate": 3.541666666666667e-05,
      "loss": 14.1606,
      "step": 16
    },
    {
      "epoch": 17.0,
      "grad_norm": 8.095199584960938,
      "learning_rate": 3.4375e-05,
      "loss": 13.421,
      "step": 17
    },
    {
      "epoch": 18.0,
      "grad_norm": 8.32833480834961,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 13.5803,
      "step": 18
    },
    {
      "epoch": 19.0,
      "grad_norm": 8.649226188659668,
      "learning_rate": 3.229166666666667e-05,
      "loss": 13.4767,
      "step": 19
    },
    {
      "epoch": 20.0,
      "grad_norm": 8.523102760314941,
      "learning_rate": 3.125e-05,
      "loss": 13.337,
      "step": 20
    },
    {
      "epoch": 21.0,
      "grad_norm": 7.345699310302734,
      "learning_rate": 3.0208333333333334e-05,
      "loss": 13.2175,
      "step": 21
    },
    {
      "epoch": 22.0,
      "grad_norm": 8.67848014831543,
      "learning_rate": 2.916666666666667e-05,
      "loss": 13.1671,
      "step": 22
    },
    {
      "epoch": 23.0,
      "grad_norm": 9.13546085357666,
      "learning_rate": 2.8125000000000003e-05,
      "loss": 12.9681,
      "step": 23
    },
    {
      "epoch": 24.0,
      "grad_norm": 9.28392505645752,
      "learning_rate": 2.7083333333333332e-05,
      "loss": 13.1719,
      "step": 24
    },
    {
      "epoch": 25.0,
      "grad_norm": 10.61120891571045,
      "learning_rate": 2.604166666666667e-05,
      "loss": 12.5626,
      "step": 25
    },
    {
      "epoch": 26.0,
      "grad_norm": 8.344752311706543,
      "learning_rate": 2.5e-05,
      "loss": 12.3534,
      "step": 26
    },
    {
      "epoch": 27.0,
      "grad_norm": 12.729973793029785,
      "learning_rate": 2.3958333333333334e-05,
      "loss": 12.7283,
      "step": 27
    },
    {
      "epoch": 28.0,
      "grad_norm": 10.958677291870117,
      "learning_rate": 2.2916666666666667e-05,
      "loss": 11.8101,
      "step": 28
    },
    {
      "epoch": 29.0,
      "grad_norm": 11.99216079711914,
      "learning_rate": 2.1875e-05,
      "loss": 12.5343,
      "step": 29
    },
    {
      "epoch": 30.0,
      "grad_norm": 9.02353572845459,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 12.5255,
      "step": 30
    },
    {
      "epoch": 31.0,
      "grad_norm": 12.35068416595459,
      "learning_rate": 1.9791666666666665e-05,
      "loss": 12.1885,
      "step": 31
    },
    {
      "epoch": 32.0,
      "grad_norm": 11.101614952087402,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 11.9527,
      "step": 32
    },
    {
      "epoch": 33.0,
      "grad_norm": 9.970819473266602,
      "learning_rate": 1.7708333333333335e-05,
      "loss": 12.2102,
      "step": 33
    },
    {
      "epoch": 34.0,
      "grad_norm": 11.750537872314453,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 12.4199,
      "step": 34
    },
    {
      "epoch": 35.0,
      "grad_norm": 11.057499885559082,
      "learning_rate": 1.5625e-05,
      "loss": 11.7642,
      "step": 35
    },
    {
      "epoch": 36.0,
      "grad_norm": 10.618595123291016,
      "learning_rate": 1.4583333333333335e-05,
      "loss": 11.569,
      "step": 36
    },
    {
      "epoch": 37.0,
      "grad_norm": 11.33072566986084,
      "learning_rate": 1.3541666666666666e-05,
      "loss": 11.5181,
      "step": 37
    },
    {
      "epoch": 38.0,
      "grad_norm": 11.460241317749023,
      "learning_rate": 1.25e-05,
      "loss": 11.8101,
      "step": 38
    },
    {
      "epoch": 39.0,
      "grad_norm": 11.964004516601562,
      "learning_rate": 1.1458333333333333e-05,
      "loss": 11.7781,
      "step": 39
    },
    {
      "epoch": 40.0,
      "grad_norm": 10.746073722839355,
      "learning_rate": 1.0416666666666668e-05,
      "loss": 11.6929,
      "step": 40
    },
    {
      "epoch": 41.0,
      "grad_norm": 11.534934997558594,
      "learning_rate": 9.375000000000001e-06,
      "loss": 11.6164,
      "step": 41
    },
    {
      "epoch": 42.0,
      "grad_norm": 11.987802505493164,
      "learning_rate": 8.333333333333334e-06,
      "loss": 11.9102,
      "step": 42
    },
    {
      "epoch": 43.0,
      "grad_norm": 10.657821655273438,
      "learning_rate": 7.2916666666666674e-06,
      "loss": 11.1073,
      "step": 43
    },
    {
      "epoch": 44.0,
      "grad_norm": 11.65597915649414,
      "learning_rate": 6.25e-06,
      "loss": 11.7492,
      "step": 44
    },
    {
      "epoch": 45.0,
      "grad_norm": 13.427328109741211,
      "learning_rate": 5.208333333333334e-06,
      "loss": 11.29,
      "step": 45
    },
    {
      "epoch": 46.0,
      "grad_norm": 11.641569137573242,
      "learning_rate": 4.166666666666667e-06,
      "loss": 11.1841,
      "step": 46
    },
    {
      "epoch": 47.0,
      "grad_norm": 10.881723403930664,
      "learning_rate": 3.125e-06,
      "loss": 11.2418,
      "step": 47
    },
    {
      "epoch": 48.0,
      "grad_norm": 9.96369743347168,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 11.1162,
      "step": 48
    },
    {
      "epoch": 49.0,
      "grad_norm": 11.093534469604492,
      "learning_rate": 1.0416666666666667e-06,
      "loss": 11.3278,
      "step": 49
    },
    {
      "epoch": 50.0,
      "grad_norm": 10.786648750305176,
      "learning_rate": 0.0,
      "loss": 11.9366,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 50,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2266889011200.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
